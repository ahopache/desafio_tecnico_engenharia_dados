# ============================================================================
# Arquivo de Configuração - SiCooperative Data Lake POC
# ============================================================================
# IMPORTANTE: Copie este arquivo para .env e ajuste os valores conforme necessário
# Comando: cp .env.example .env
#
# SEGURANÇA: NUNCA commite o arquivo .env com credenciais reais!
# ============================================================================

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DO MYSQL
# ----------------------------------------------------------------------------

# Host do MySQL (use 'mysql' se estiver usando Docker Compose)
MYSQL_HOST=localhost

# Porta do MySQL
MYSQL_PORT=3306

# Nome do banco de dados
MYSQL_DATABASE=sicooperative_db

# Usuário do MySQL
MYSQL_USER=root

# Senha do MySQL (GERE UMA SENHA FORTE E ÚNICA!)
MYSQL_PASS=YOUR_SECURE_MYSQL_PASSWORD_HERE

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DO SPARK
# ----------------------------------------------------------------------------

# Nome da aplicação Spark
SPARK_APP_NAME=SiCooperative-ETL

# Master do Spark (local[*] usa todos os cores disponíveis)
SPARK_MASTER=local[*]

# Memória do driver
SPARK_DRIVER_MEMORY=2g

# Memória do executor
SPARK_EXECUTOR_MEMORY=2g

# Habilitar otimização adaptativa
SPARK_SQL_ADAPTIVE_ENABLED=true

# Habilitar coalesce de partições
SPARK_SQL_ADAPTIVE_COALESCE_PARTITIONS=true

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DE OUTPUT
# ----------------------------------------------------------------------------

# Diretório de saída para o CSV
OUTPUT_DIR=./output

# Nome do arquivo de saída
OUTPUT_FILENAME=movimento_flat.csv

# Modo de escrita (overwrite ou append)
OUTPUT_MODE=overwrite

# Incluir header no CSV
OUTPUT_HEADER=true

# Delimitador do CSV
OUTPUT_DELIMITER=,

# Encoding do arquivo
OUTPUT_ENCODING=UTF-8

# Formatos de saída (csv,parquet ou ambos separados por vírgula)
OUTPUT_FORMAT=csv,parquet

# Configurações do Parquet (opções: none, snappy, gzip, lzo, brotli, lz4)
PARQUET_COMPRESSION=snappy

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DE LOGGING
# ----------------------------------------------------------------------------

# Nível de log (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DE LGPD (PROTEÇÃO DE DADOS PESSOAIS)
# ----------------------------------------------------------------------------

# Hash salt para anonimização (GERE UM SALT ÚNICO E SECRETO!)
# IMPORTANTE: Este salt deve ser diferente em cada ambiente (dev, staging, prod)
HASH_SALT=YOUR_UNIQUE_SECRET_SALT_HERE_32_CHARS_MIN

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DE QUALIDADE DE DADOS
# ----------------------------------------------------------------------------

# Habilitar verificações de qualidade de dados
DATA_QUALITY_CHECKS_ENABLED=true

# Limite de NULL para campos críticos (1% = 0.01)
NULL_CHECK_THRESHOLD_CARTAO=0.01

# Limite para transações negativas (0% = 0.0)
NEGATIVE_TRANSACTIONS_THRESHOLD=0.0

# Tolerância para mudança de volume (50% = 0.5)
VOLUME_CHANGE_TOLERANCE=0.5

# Arquivo de histórico de qualidade
DATA_QUALITY_HISTORY_FILE=data_quality_history.json

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DE OBSERVABILIDADE
# ----------------------------------------------------------------------------

# Habilitar sistema de observabilidade e métricas
OBSERVABILITY_ENABLED=true

# Prometheus Pushgateway (opcional - deixe vazio para desabilitar)
# PROMETHEUS_GATEWAY_URL=http://localhost:9091

# Nome do job no Prometheus
PROMETHEUS_JOB_NAME=sicooperative-etl

# Habilitar logs detalhados de métricas
METRICS_DETAILED_LOGGING=false

# Arquivo de exportação de métricas (formato JSON)
METRICS_EXPORT_FILE=pipeline_metrics.json

# ----------------------------------------------------------------------------
# CONFIGURAÇÕES DE PARTICIONAMENTO JDBC
# ----------------------------------------------------------------------------

# Habilitar particionamento JDBC otimizado
JDBC_PARTITIONING_ENABLED=true

# Tamanho alvo por partição (em registros)
JDBC_TARGET_RECORDS_PER_PARTITION=25000

# Número máximo de conexões JDBC por tabela
JDBC_MAX_CONNECTIONS_PER_TABLE=10

# Timeout para queries de estatísticas (segundos)
JDBC_STATS_QUERY_TIMEOUT=30

# ========================================================================
# INSTRUÇÕES DE SEGURANÇA
# ========================================================================
#
# 1. Gere senhas fortes e únicas para cada ambiente
# 2. Use ferramentas como: openssl rand -hex 32
# 3. Nunca compartilhe este arquivo .env
# 4. Em produção, use sistemas de gerenciamento de segredos (Vault, AWS Secrets Manager, etc.)
# 5. Monitore acessos e alterações em arquivos sensíveis
#
# ========================================================================