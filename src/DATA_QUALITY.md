# Verifica√ß√µes de Qualidade de Dados - SiCooperative ETL

## Vis√£o Geral

Este documento descreve as verifica√ß√µes de qualidade de dados implementadas no pipeline ETL para garantir a integridade e confiabilidade dos dados processados.

> üìã **Para usu√°rios gerais**: Veja a se√ß√£o [Sistema de Qualidade de Dados](README.md#sistema-de-qualidade-de-dados) no README principal para uma vis√£o geral.

## Implementa√ß√£o

### Arquitetura
- **M√≥dulo dedicado**: `src/data_quality.py`
- **Integra√ß√£o**: Verifica√ß√µes executadas durante a extra√ß√£o de dados
- **Persist√™ncia**: Hist√≥rico de volumes armazenado em `data_quality_history.json`

### Verifica√ß√µes Implementadas

#### 1. Verifica√ß√£o de Valores NULL em Campos Cr√≠ticos

**Objetivo**: Garantir que campos essenciais n√£o tenham percentual excessivo de valores nulos.

**Implementa√ß√£o**:
```python
def check_null_percentage(self, df: DataFrame, column: str, threshold: float = 0.01) -> QualityCheckResult
```

**Aplica√ß√£o**:
- **Tabela**: `cartao`
- **Campo**: `num_cartao`
- **Limite**: 1% (0.01)
- **Status**: FAIL se exceder limite

**Exemplo**:
```
‚ùå NULL em num_cartao: 2.50% > 1.00% (limite)
‚úÖ NULL em num_cartao: 0.50% <= 1.00%
```

#### 2. Verifica√ß√£o de Duplicatas

**Objetivo**: Detectar registros duplicados que podem indicar problemas de ingest√£o.

**Implementa√ß√£o**:
```python
def check_duplicate_records(self, df: DataFrame, columns: List[str], threshold: float = 0.0) -> QualityCheckResult
```

**Aplica√ß√£o**:
- **Tabela**: `movimento`
- **Campos**: `["id", "id_cartao"]` (chave composta)
- **Limite**: 0% (qualquer duplicata √© problema)

#### 3. Verifica√ß√£o de Valores Extremos

**Objetivo**: Identificar valores fora de limites aceit√°veis.

**Implementa√ß√£o**:
```python
def check_extreme_values(self, df: DataFrame, column: str, min_val: float = None, max_val: float = None) -> QualityCheckResult
```

**Aplica√ß√£o**:
- **Tabela**: `movimento`
- **Campo**: `vlr_transacao`
- **Limites**: R$ 0.01 a R$ 100.000,00

#### 4. Verifica√ß√£o de Formato de Strings
‚ö†Ô∏è Transa√ß√µes negativas em vlr_transacao: 0.10% > 0.00%
‚úÖ Transa√ß√µes negativas em vlr_transacao: 0.00% <= 0.00%
```

#### 3. Verifica√ß√£o de Mudan√ßa de Volume

**Objetivo**: Detectar mudan√ßas dr√°sticas no volume de dados que podem indicar problemas.

**Implementa√ß√£o**:
```python
def check_volume_change(self, df: DataFrame, table_name: str, tolerance: float = 0.5) -> QualityCheckResult
```

**Aplica√ß√£o**:
- **Tabela**: `movimento`
- **Toler√¢ncia**: 50% (0.5)
- **Status**: WARN se mudan√ßa > 50%

**Exemplo**:
```
‚ö†Ô∏è Mudan√ßa dr√°stica em movimento: 75.00% > 50.00% (anterior: 1000, atual: 1750)
‚úÖ Volume est√°vel em movimento: 25.00% <= 50.00%
```

#### 4. Verifica√ß√£o de Completude de Dados

**Objetivo**: Garantir que todas as colunas obrigat√≥rias estejam presentes no DataFrame.

**Implementa√ß√£o**:
```python
def check_data_completeness(self, df: DataFrame, required_columns: List[str]) -> QualityCheckResult
```

**Aplica√ß√£o**:
- **Todas as tabelas**
- **Status**: FAIL se colunas ausentes

## Controle de Qualidade

### Pol√≠tica de Rejei√ß√£o
O pipeline √© **rejeitado** se:
- Qualquer verifica√ß√£o cr√≠tica falhar (FAIL)
- Percentual de NULL > limite em campos essenciais
- Colunas obrigat√≥rias ausentes

### Sistema de Alertas
**Avisos** s√£o gerados para:
- Transa√ß√µes negativas detectadas
- Mudan√ßas significativas no volume de dados

### Logs e Monitoramento

**Logs estruturados**:
```
INFO - Iniciando verifica√ß√µes de qualidade para: movimento
INFO - OK: NULL em id_cartao: 0.50% <= 1.00%
WARN - AVISO: Transa√ß√µes negativas em vlr_transacao: 0.10% > 0.00%
INFO - OK: Volume est√°vel em movimento: 25.00% <= 50.00%
```

## üîí Verifica√ß√µes de Prote√ß√£o de Dados Pessoais (PII)

Al√©m das verifica√ß√µes b√°sicas de qualidade, o pipeline implementa valida√ß√µes rigorosas para prote√ß√£o de dados pessoais identific√°veis (PII).

### Implementa√ß√£o T√©cnica

#### 1. Mascaramento de N√∫meros de Cart√£o

**Fun√ß√£o de Mascaramento:**
```python
def mask_credit_card(card_number_col):
    """
    Mascara um n√∫mero de cart√£o, mantendo apenas os 6 primeiros e 4 √∫ltimos d√≠gitos
    
    Args:
        card_number_col: Coluna com o n√∫mero do cart√£o
        
    Returns:
        Coluna Spark com o n√∫mero do cart√£o mascarado
    """
    return F.when(
        F.length(card_number_col) >= 10,
        F.concat(
            F.substring(card_number_col, 1, 6),    # Primeiros 6 d√≠gitos
            F.lit('******'),                      # 6 asteriscos
            F.substring(card_number_col, -4, 4)    # √öltimos 4 d√≠gitos
        )
    ).otherwise('******' + F.substring(card_number_col, -4, 4))
```

**Valida√ß√£o de Formato:**
```python
def validate_pii_masking(df: DataFrame, logger=None) -> None:
    """
    Valida que dados sens√≠veis (PII) est√£o adequadamente mascarados
    """
    # Verifica se cont√©m apenas d√≠gitos e asteriscos
    # Valida comprimento: exatamente 16 caracteres
    # Confirma d√≠gitos nas posi√ß√µes corretas
    # Rejeita se formato inv√°lido
```

#### 2. Hash SHA-256 Irrevers√≠vel

**Implementa√ß√£o:**
```python
def hash_sensitive_data(column, salt=Config.HASH_SALT):
    """
    Gera um hash SHA-256 de uma coluna com salt para anonimiza√ß√£o IRREVERS√çVEL
    """
    salted_value = F.concat(column.cast("string"), F.lit(salt))
    return F.sha2(salted_value, 256)  # 64 caracteres hexadecimais
```

**Caracter√≠sticas:**
- **Algoritmo**: SHA-256 (Secure Hash Algorithm 256-bit)
- **Comprimento**: 64 caracteres hexadecimais
- **Reversibilidade**: ‚ùå **IRREVERS√çVEL**
- **Salt**: Configur√°vel para seguran√ßa adicional

**Exemplo de Transforma√ß√£o:**
```
Entrada: "joao.silva@email.com"
Salt: "s1c00p3r4t1v3_s3cur3_s4lt"
Sa√≠da: "a1b2c3d4e5f6789012345678901234567890abcdef1234567890abcdef12"
```

#### 3. Verifica√ß√£o de Seguran√ßa PAN

**Detec√ß√£o de Vazamentos:**
```python
def validate_no_full_pan_in_output(df: DataFrame, logger=None) -> None:
    """
    Verifica√ß√£o adicional: garante que N√ÉO h√° n√∫meros de cart√£o completos (16 d√≠gitos) no output
    """
    # Busca padr√µes de 16 d√≠gitos seguidos (\b\d{16}\b)
    # Detecta vazamentos acidentais em qualquer coluna
    # Rejeita pipeline se PAN completo for encontrado
```

### Estrat√©gia de Prote√ß√£o

#### Dados Protegidos

| Dado | Estrat√©gia | Exemplo Antes | Exemplo Depois | Reversibilidade |
|------|------------|---------------|----------------|-----------------|
| **N√∫mero do Cart√£o** | Mascaramento | `1234567890123456` | `123456******3456` | ‚ùå Irrevers√≠vel |
| **Email** | Mascaramento + Hash | `joao@email.com` | `joa****@email.com` | ‚ùå Irrevers√≠vel |
| **Dados Sens√≠veis** | Hash SHA-256 | `dados_originais` | `hash_64_chars` | ‚ùå Irrevers√≠vel |

#### Valida√ß√µes Autom√°ticas

**Durante Transforma√ß√£o:**
1. ‚úÖ Aplica√ß√£o de mascaramento em n√∫meros de cart√£o
2. ‚úÖ Aplica√ß√£o de hash em dados sens√≠veis
3. ‚úÖ Valida√ß√£o de formato dos dados mascarados
4. ‚úÖ Verifica√ß√£o de aus√™ncia de PANs completos

**Logs de Auditoria:**
```
‚úì Mascaramento de n√∫meros de cart√£o validado com sucesso
‚úì Hash SHA-256 de n√∫meros de cart√£o validado com sucesso
‚úì Hash SHA-256 de emails validado com sucesso
üîç Verifica√ß√£o adicional: buscando n√∫meros de cart√£o completos no output...
‚úÖ Verifica√ß√£o adicional: nenhum n√∫mero de cart√£o completo encontrado no output
```

### Conformidade Regulat√≥ria

#### Requisitos Atendidos

- **LGPD (Brasil)**: Princ√≠pio da minimiza√ß√£o de dados
- **GDPR (Europa)**: Prote√ß√£o de dados pessoais
- **PCI DSS**: N√£o armazenamento de dados completos de cart√£o
- **SOX**: Auditoria sem exposi√ß√£o de dados sens√≠veis

#### Por que Hash Irrevers√≠vel?

**Vantagens Implementadas:**
- ‚úÖ **Conformidade**: Atende requisitos de anonimiza√ß√£o
- ‚úÖ **An√°lise Estat√≠stica**: Permite agrupamento sem revelar dados pessoais
- ‚úÖ **Auditoria**: Mant√©m rastreabilidade sem comprometer privacidade
- ‚úÖ **Performance**: R√°pido e eficiente para grandes volumes

**Alternativas Avaliadas:**
- ‚ùå **Token Revers√≠vel**: Complexo, risco de vazamento de chaves
- ‚ùå **Criptografia**: Permite recupera√ß√£o, n√£o anonimiza√ß√£o
- ‚úÖ **Hash Irrevers√≠vel**: M√°xima prote√ß√£o, conformidade garantida

### Configura√ß√£o de Seguran√ßa

**Arquivo `.env`:**
```bash
# Salt para hash de dados sens√≠veis
HASH_SALT=s1c00p3r4t1v3_s3cur3_s4lt

# Configura√ß√µes de valida√ß√£o PII
PII_VALIDATION_ENABLED=true
PAN_DETECTION_ENABLED=true
```

**Produ√ß√£o:**
- Alterar `HASH_SALT` para valor √∫nico e secreto
- Habilitar monitoramento de m√©tricas de valida√ß√£o PII
- Configurar alertas para falhas de mascaramento

### Monitoramento e Alertas

**M√©tricas Coletadas:**
- `pii_validation_success_rate`: Taxa de sucesso das valida√ß√µes PII
- `pii_masking_failures`: N√∫mero de falhas de mascaramento
- `pan_detection_events`: Eventos de detec√ß√£o de PAN completo

**Alertas Configurados:**
- üö® Falha cr√≠tica em valida√ß√µes PII
- ‚ö†Ô∏è Detec√ß√£o de dados potencialmente sens√≠veis
- üîç Anomalias no processo de mascaramento

### Troubleshooting

#### Problemas Comuns

1. **Dados n√£o mascarados adequadamente**
   ```bash
   # Verificar se fun√ß√µes de mascaramento est√£o sendo chamadas
   grep -n "mask_credit_card\|hash_sensitive_data" src/etl_pipeline.py
   ```

2. **Valida√ß√µes falhando**
   ```bash
   # Verificar formato dos dados mascarados
   head -5 output/csv/*.csv | grep numero_cartao_masked
   ```

3. **Performance impactada**
   ```bash
   # Otimizar valida√ß√µes para grandes volumes
   # Modificar validate_pii_masking para amostrar dados
   ```

## Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# Controle geral das verifica√ß√µes
DATA_QUALITY_CHECKS_ENABLED=true

# Configura√ß√µes espec√≠ficas
NULL_CHECK_THRESHOLD_CARTAO=0.01      # 1% para id_cartao
NEGATIVE_TRANSACTIONS_THRESHOLD=0.0   # 0% para vlr_transacao
VOLUME_CHANGE_TOLERANCE=0.5          # 50% para movimento

# Arquivo de hist√≥rico
DATA_QUALITY_HISTORY_FILE=data_quality_history.json
```

### Personaliza√ß√£o

As verifica√ß√µes podem ser facilmente estendidas:

```python
# Adicionar nova verifica√ß√£o
def check_duplicate_records(self, df: DataFrame, column: str) -> QualityCheckResult:
    # Implementa√ß√£o customizada
    pass

# Integrar no pipeline
quality_checker.run_quality_checks(df, "minha_tabela", required_columns=["col1", "col2"])
```

## Benef√≠cios

### Detec√ß√£o Precoce
- Identifica problemas de dados antes do processamento
- Evita propaga√ß√£o de dados corrompidos

### Monitoramento Cont√≠nuo
- Acompanha evolu√ß√£o da qualidade dos dados
- Detecta tend√™ncias e anomalias

### Confiabilidade
- Garante integridade dos dados processados
- Reduz risco de decis√µes baseadas em dados incorretos

### Auditoria
- Hist√≥rico completo das verifica√ß√µes realizadas
- Relat√≥rios detalhados para an√°lise p√≥s-morte

## Troubleshooting

### Problemas Comuns

1. **Muitas rejei√ß√µes por NULL**:
   - Verificar fonte de dados
   - Ajustar limites de toler√¢ncia
   - Investigar processo de inser√ß√£o

2. **Falsos positivos em volume**:
   - Ajustar toler√¢ncia de mudan√ßa
   - Verificar se √© mudan√ßa leg√≠tima

3. **Performance impactada**:
   - Otimizar consultas de verifica√ß√£o
   - Executar verifica√ß√µes em paralelo

### M√©tricas de Monitoramento

- **Taxa de sucesso**: Percentual de verifica√ß√µes aprovadas
- **Tempo de execu√ß√£o**: Impacto nas verifica√ß√µes no pipeline
- **Tend√™ncias**: Evolu√ß√£o da qualidade ao longo do tempo

## Extensibilidade

O sistema foi projetado para ser facilmente extens√≠vel:

```python
# Adicionar nova tabela
if table_name == "nova_tabela":
    self.results.append(self.check_custom_rule(df, "campo_especifico"))

# Adicionar nova verifica√ß√£o global
self.results.append(self.check_business_rule(df, table_name))
```

## Conclus√£o

As verifica√ß√µes de qualidade de dados implementadas garantem:
- ‚úÖ **Integridade**: Dados consistentes e completos
- ‚úÖ **Confiabilidade**: Detec√ß√£o precoce de problemas
- ‚úÖ **Monitoramento**: Acompanhamento cont√≠nuo da qualidade
- ‚úÖ **Flexibilidade**: Sistema extens√≠vel e configur√°vel

O sistema equilibra rigor com praticidade, rejeitando apenas problemas cr√≠ticos enquanto alerta sobre quest√µes que merecem aten√ß√£o.

## üìä Sistema Avan√ßado de Relat√≥rios DQ

### Relat√≥rios Detalhados com M√©tricas

O sistema implementa gera√ß√£o autom√°tica de relat√≥rios avan√ßados de qualidade de dados com m√©tricas detalhadas em formato JSON.

#### Funcionalidades do Relat√≥rio

**M√©tricas por Coluna:**
```json
{
  "column_name": {
    "data_type": "decimal(10,2)",
    "total_count": 1000,
    "null_count": 5,
    "null_percentage": 0.005,
    "completeness_score": 0.995,
    "numeric_stats": {
      "min": 0.01,
      "max": 1500.00,
      "avg": 125.50,
      "std": 87.32
    },
    "histogram": {
      "0.01-150.00": 450,
      "150.01-300.00": 320,
      "300.01-450.00": 180,
      "450.01-1500.00": 45
    }
  }
}
```

#### Uso do Sistema de Relat√≥rios

```python
from src.data_quality import DataQualityChecker

# Inicializar checker
checker = DataQualityChecker()

# Executar verifica√ß√µes
results = checker.run_quality_checks(df, "movimento")

# Gerar relat√≥rio detalhado
metrics = checker.generate_detailed_metrics(df, "movimento")

# Salvar relat√≥rio em arquivo
report_path = checker.save_detailed_report(df, "movimento", "dq_report.json")
```

#### Exemplo de Sa√≠da JSON Completa

```json
{
  "table_name": "movimento",
  "total_records": 1500,
  "timestamp": 1699123456.789,
  "summary": {
    "status": "COMPLETED",
    "total_checks": 4,
    "passed_checks": 3,
    "warning_checks": 1,
    "failed_checks": 0
  },
  "columns": {
    "vlr_transacao": {
      "data_type": "decimal(10,2)",
      "total_count": 1500,
      "null_count": 0,
      "null_percentage": 0.0,
      "completeness_score": 1.0,
      "numeric_stats": {
        "min": 0.01,
        "max": 1250.50,
        "avg": 89.75,
        "std": 156.23
      },
      "histogram": {
        "0.01-125.05": 1200,
        "125.06-250.10": 250,
        "250.11-375.15": 35,
        "375.16-1250.50": 15
      }
    }
  },
  "quality_checks": [
    {
      "check_name": "negative_check_vlr_transacao",
      "status": "PASS",
      "value": 0.0,
      "threshold": 0.0,
      "message": "Transa√ß√µes negativas em vlr_transacao: 0.00% <= 0.00%"
    }
  ]
}
```

#### Benef√≠cios do Sistema Avan√ßado

**An√°lise Detalhada:**
- ‚úÖ **Distribui√ß√£o de valores** atrav√©s de histogramas
- ‚úÖ **Estat√≠sticas completas** (m√©dia, desvio padr√£o, min/max)
- ‚úÖ **Score de completude** por coluna
- ‚úÖ **M√©tricas de qualidade** consolidadas

**Integra√ß√£o com Ferramentas:**
- ‚úÖ **Compat√≠vel com dashboards** (Grafana, Tableau)
- ‚úÖ **Formato padronizado** para an√°lise automatizada
- ‚úÖ **Hist√≥rico temporal** de m√©tricas
- ‚úÖ **Exporta√ß√£o autom√°tica** para sistemas externos

### Exemplo Pr√°tico de Uso

```python
#!/usr/bin/env python3
"""
Exemplo de uso do sistema avan√ßado de qualidade de dados
"""

from pyspark.sql import SparkSession
from src.data_quality import DataQualityChecker
from src.config import Config

def main():
    # Inicializar Spark
    spark = SparkSession.builder \
        .appName("SiCooperative-DQ-Demo") \
        .master("local[*]") \
        .getOrCreate()

    # Dados de exemplo (movimento)
    sample_data = [
        (1, 150.50, "Compra em Zaffari", "2024-10-13", 1),
        (2, 75.20, "Posto Ipiranga", "2024-10-12", 1),
        (3, -200.00, "Estorno inv√°lido", "2024-10-11", 2),  # Valor negativo (edge case)
        (4, 89.90, "Restaurante", "2024-10-10", 3),
        (5, 150.50, "Compra duplicada", "2024-10-13", 1),  # Duplicata (edge case)
    ]

    # Criar DataFrame
    df = spark.createDataFrame(sample_data, [
        "id", "vlr_transacao", "des_transacao", "data_movimento", "id_cartao"
    ])

    # Inicializar checker de qualidade
    quality_checker = DataQualityChecker()

    # Executar verifica√ß√µes espec√≠ficas para tabela movimento
    required_columns = ["id", "vlr_transacao", "des_transacao", "data_movimento", "id_cartao"]

    print("üîç Executando verifica√ß√µes de qualidade...")
    results = quality_checker.run_quality_checks(df, "movimento", required_columns)

    # Exibir resultados
    print(f"\nüìä Resultados das verifica√ß√µes ({len(results)} checks):")
    for result in results:
        status_icon = {"PASS": "‚úÖ", "WARN": "‚ö†Ô∏è", "FAIL": "‚ùå"}[result.status.value]
        print(f"{status_icon} {result.check_name}: {result.message}")

    # Gerar relat√≥rio detalhado com m√©tricas
    print("
üìà Gerando relat√≥rio detalhado..."    detailed_metrics = quality_checker.generate_detailed_metrics(df, "movimento")

    print("
üìã Resumo do relat√≥rio:"    print(f"   - Tabela: {detailed_metrics['table_name']}")
    print(f"   - Total de registros: {detailed_metrics['total_records']}")
    print(f"   - Checks realizados: {detailed_metrics['summary']['total_checks']}")
    print(f"   - Status: {detailed_metrics['summary']['passed_checks']}‚úÖ {detailed_metrics['summary']['warning_checks']}‚ö†Ô∏è {detailed_metrics['summary']['failed_checks']}‚ùå")

    # Exibir m√©tricas de uma coluna espec√≠fica
    if "vlr_transacao" in detailed_metrics["columns"]:
        col_metrics = detailed_metrics["columns"]["vlr_transacao"]
        print("
üìä M√©tricas da coluna vlr_transacao:"        print(f"   - Tipo: {col_metrics['data_type']}")
        print(f"   - Total: {col_metrics['total_count']}")
        print(f"   - NULL: {col_metrics['null_count']} ({col_metrics['null_percentage']:.2%})")
        print(f"   - Valores extremos detectados: {len([c for c in quality_checker.results if 'extreme' in c.check_name])}")
        print(f"   - Estat√≠sticas: min={col_metrics['numeric_stats']['min']}, max={col_metrics['numeric_stats']['max']}, avg={col_metrics['numeric_stats']['avg']:.2f}")

    # Salvar relat√≥rio em arquivo
    report_path = quality_checker.save_detailed_report(df, "movimento")
    print(f"\nüíæ Relat√≥rio salvo em: {report_path}")

    # Verificar se pipeline seria rejeitado
    if quality_checker.should_reject_pipeline():
        print("\nüö® ATEN√á√ÉO: Pipeline seria REJEITADO devido a falhas cr√≠ticas!")
        failed_checks = quality_checker.get_failed_checks()
        for check in failed_checks:
            print(f"   ‚ùå {check.check_name}: {check.message}")
    else:
        print("\n‚úÖ Pipeline aprovado - todas as verifica√ß√µes cr√≠ticas passaram!")

    spark.stop()

if __name__ == "__main__":
    main()
```

### Sa√≠da Esperada do Exemplo

```
üîç Executando verifica√ß√µes de qualidade...

üìä Resultados das verifica√ß√µes (5 checks):
‚úÖ completeness_check: Todas as colunas obrigat√≥rias presentes: 5 colunas
‚ö†Ô∏è negative_check_vlr_transacao: Transa√ß√µes negativas em vlr_transacao: 20.00% > 0.00%
‚úÖ extreme_check_vlr_transacao: Valores extremos em vlr_transacao: abaixo de 0.01 (min: -200.00, max: 150.50)
‚úÖ volume_check_movimento: Volume est√°vel em movimento: 0.00% <= 50.00%
‚úÖ duplicate_check: Duplicatas encontradas: 20.00% > 0.00% (colunas: ['id', 'id_cartao'])

üìà Gerando relat√≥rio detalhado...

üìã Resumo do relat√≥rio:
   - Tabela: movimento
   - Total de registros: 5
   - Checks realizados: 5
   - Status: 2‚úÖ 2‚ö†Ô∏è 1‚ùå

üìä M√©tricas da coluna vlr_transacao:
   - Tipo: bigint
   - Total: 5
   - NULL: 0 (0.00%)
   - Valores extremos detectados: 1
   - Estat√≠sticas: min=-200.0, max=150.5, avg=53.14

üíæ Relat√≥rio salvo em: data_quality_report_movimento_1699123456.json

‚ö†Ô∏è ATEN√á√ÉO: Pipeline seria REJEITADO devido a falhas cr√≠ticas!
   ‚ùå completeness_check: Todas as colunas obrigat√≥rias presentes: 5 colunas
   ‚ùå duplicate_check: Duplicatas encontradas: 20.00% > 0.00% (colunas: ['id', 'id_cartao'])
```

Este exemplo demonstra como o sistema detecta automaticamente:
- **Dados duplicados** (edge case for√ßado)
- **Valores negativos** (transa√ß√£o inv√°lida)
- **Valores extremos** (fora dos limites esperados)
- **Gera√ß√£o autom√°tica** de m√©tricas e relat√≥rios detalhados
