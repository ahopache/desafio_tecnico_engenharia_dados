"""
M√≥dulo de Utilidades
Fun√ß√µes auxiliares para logging, valida√ß√£o e opera√ß√µes comuns
"""

import logging
import sys
import re
from typing import Optional
from datetime import datetime
from pyspark.sql import DataFrame, SparkSession, functions as F

from config import Config


def setup_logger(name: str = __name__, level: Optional[str] = None) -> logging.Logger:
    """
    Configura e retorna um logger
    
    Args:
        name: Nome do logger
        level: N√≠vel de log (DEBUG, INFO, WARNING, ERROR)
    
    Returns:
        logging.Logger: Logger configurado
    """
    log_level = level or Config.LOG_LEVEL
    
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # Evitar duplica√ß√£o de handlers
    if not logger.handlers:
        # Handler para console
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, log_level.upper()))
        
        # Formatter
        formatter = logging.Formatter(
            Config.LOG_FORMAT,
            datefmt=Config.LOG_DATE_FORMAT
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
    
    return logger


def validate_mysql_connection(spark: SparkSession) -> bool:
    """
    Valida a conex√£o com o MySQL
    
    Args:
        spark: Sess√£o Spark ativa
    
    Returns:
        bool: True se a conex√£o foi bem-sucedida
    
    Raises:
        Exception: Se n√£o conseguir conectar ao MySQL
    """
    logger = setup_logger(__name__)
    
    try:
        logger.info("Validando conex√£o com MySQL...")
        
        # Tenta ler uma tabela simples
        test_query = "(SELECT 1 AS test) AS test_table"
        
        df = spark.read \
            .format("jdbc") \
            .option("url", Config.get_mysql_jdbc_url()) \
            .option("dbtable", test_query) \
            .option("user", Config.MYSQL_USER) \
            .option("password", Config.MYSQL_PASSWORD) \
            .option("driver", "com.mysql.cj.jdbc.Driver") \
            .load()
        
        # For√ßa a execu√ß√£o da query
        count = df.count()
        
        if count == 1:
            logger.info("‚úì Conex√£o com MySQL validada com sucesso!")
            return True
        else:
            raise Exception("Resultado inesperado na valida√ß√£o")
            
    except Exception as e:
        logger.error(f"‚úó Erro ao conectar ao MySQL: {str(e)}")
        raise


def validate_dataframe(
    df: DataFrame,
    name: str,
    min_rows: int = 1,
    required_columns: Optional[list] = None
) -> None:
    """
    Valida um DataFrame
    
    Args:
        df: DataFrame a ser validado
        name: Nome do DataFrame (para logging)
        min_rows: N√∫mero m√≠nimo de linhas esperado
        required_columns: Lista de colunas obrigat√≥rias
    
    Raises:
        ValueError: Se a valida√ß√£o falhar
    """
    logger = setup_logger(__name__)
    
    # Validar se DataFrame n√£o est√° vazio
    count = df.count()
    if count < min_rows:
        raise ValueError(
            f"DataFrame '{name}' tem apenas {count} linhas "
            f"(m√≠nimo esperado: {min_rows})"
        )
    
    # Validar colunas obrigat√≥rias
    if required_columns:
        missing_cols = set(required_columns) - set(df.columns)
        if missing_cols:
            raise ValueError(
                f"DataFrame '{name}' est√° faltando colunas: {missing_cols}"
            )
    
    logger.info(f"‚úì DataFrame '{name}' validado: {count} linhas, {len(df.columns)} colunas")


def log_dataframe_info(df: DataFrame, name: str, sample_rows: int = 5) -> None:
    """
    Loga informa√ß√µes sobre um DataFrame
    
    Args:
        df: DataFrame
        name: Nome do DataFrame
        sample_rows: N√∫mero de linhas para mostrar no sample
    """
    logger = setup_logger(__name__)
    
    logger.info(f"\n{'=' * 70}")
    logger.info(f"DataFrame: {name}")
    logger.info(f"{'=' * 70}")
    logger.info(f"Total de linhas: {df.count()}")
    logger.info(f"Total de colunas: {len(df.columns)}")
    logger.info(f"\nSchema:")
    df.printSchema()
    logger.info(f"\nAmostra ({sample_rows} linhas):")
    df.show(sample_rows, truncate=False)
    logger.info(f"{'=' * 70}\n")


def format_duration(seconds: float) -> str:
    """
    Formata dura√ß√£o em segundos para formato leg√≠vel
    
    Args:
        seconds: Dura√ß√£o em segundos
    
    Returns:
        str: Dura√ß√£o formatada (ex: "2m 30s")
    """
    if seconds < 60:
        return f"{seconds:.2f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}m {secs:.2f}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = seconds % 60
        return f"{hours}h {minutes}m {secs:.2f}s"


def create_output_directory(path: str) -> None:
    """
    Cria o diret√≥rio de sa√≠da se n√£o existir
    
    Args:
        path: Caminho do diret√≥rio
    """
    import os
    
    logger = setup_logger(__name__)
    
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)
        logger.info(f"‚úì Diret√≥rio de sa√≠da criado: {path}")
    else:
        logger.info(f"‚úì Diret√≥rio de sa√≠da j√° existe: {path}")


def get_timestamp() -> str:
    """
    Retorna timestamp atual formatado
    
    Returns:
        str: Timestamp no formato YYYY-MM-DD HH:MM:SS
    """
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def print_banner(message: str, char: str = "=") -> None:
    """
    Imprime um banner formatado
    
    Args:
        message: Mensagem a ser exibida
        char: Caractere para a borda
    """
    logger = setup_logger(__name__)
    width = 70
    
    logger.info(f"\n{char * width}")
    logger.info(f"{message.center(width)}")
    logger.info(f"{char * width}\n")


def print_statistics(stats: dict) -> None:
    """
    Imprime estat√≠sticas finais do pipeline

    Args:
        stats: Dicion√°rio com estat√≠sticas do pipeline
    """
    print("=" * 70)
    print("üìä ESTAT√çSTICAS DO PIPELINE")
    print("=" * 70)

    print(f"‚è±Ô∏è  Dura√ß√£o total: {stats.get('duracao', 'N/A')}")
    print(f"üì• Registros extra√≠dos:")
    print(f"   ‚Ä¢ Associados: {stats.get('registros_associado', 0):,}","g")
    print(f"   ‚Ä¢ Contas: {stats.get('registros_conta', 0):,}","g")
    print(f"   ‚Ä¢ Cart√µes: {stats.get('registros_cartao', 0):,}","g")
    print(f"   ‚Ä¢ Movimentos: {stats.get('registros_movimento', 0):,}","g")
    print(f"üì§ Registros finais: {stats.get('registros_final', 0):,}","g")

    # Estat√≠sticas de qualidade de dados (se dispon√≠veis)
    if 'quality_checks' in stats:
        quality_stats = stats['quality_checks']
        print(f"üîç Verifica√ß√µes de qualidade:")
        print(f"   ‚Ä¢ Total: {quality_stats.get('total', 0)}")
        print(f"   ‚Ä¢ Aprovadas: {quality_stats.get('passed', 0)}")
        print(f"   ‚Ä¢ Avisos: {quality_stats.get('warnings', 0)}")
        print(f"   ‚Ä¢ Rejei√ß√µes: {quality_stats.get('failed', 0)}")

    print("=" * 70)


class ETLException(Exception):
    """Exce√ß√£o customizada para erros do pipeline ETL"""
    pass


class ValidationException(Exception):
    """Exce√ß√£o customizada para erros de valida√ß√£o"""
    pass


def mask_credit_card(card_number_col):
    """
    Mascara um n√∫mero de cart√£o, mantendo apenas os 6 primeiros e 4 √∫ltimos d√≠gitos
    
    Args:
        card_number_col: Coluna com o n√∫mero do cart√£o
        
    Returns:
        Coluna Spark com o n√∫mero do cart√£o mascarado
    """
    return F.when(
        F.length(card_number_col) >= 10,
        F.concat(
            F.substring(card_number_col, 1, 6),
            F.lit('******'),
            F.substring(card_number_col, -4, 4)
        )
    ).otherwise('******' + F.substring(card_number_col, -4, 4))


def hash_sensitive_data(column, salt=Config.HASH_SALT):
    """
    Gera um hash SHA-256 de uma coluna com salt para anonimiza√ß√£o IRREVERS√çVEL
    
    IMPORTANTE - IRREVERS√çVEL:
    - Usa algoritmo criptogr√°fico SHA-256 que N√ÉO permite recupera√ß√£o do valor original
    - √ötil para auditoria, an√°lise e conformidade com leis de privacidade (LGPD/GDPR)
    - N√ÉO √© poss√≠vel "descriptografar" ou reverter o hash para obter dados originais
    - Cada execu√ß√£o gera o mesmo hash para o mesmo input (determin√≠stico)
    
    Args:
        column: Coluna a ser hasheada
        salt: String de salt para aumentar a seguran√ßa do hash
        
    Returns:
        Coluna Spark com o valor hasheado (string hexadecimal de 64 caracteres)
        
    Exemplo:
        Entrada: "1234567890123456"
        Salt: "s1c00p3r4t1v3_s3cur3_s4lt"
        Sa√≠da: "a1b2c3d4e5f6..." (64 caracteres hexadecimais)
    """
    # Converte para string e concatena com o salt
    salted_value = F.concat(F.coalesce(column.cast("string"), F.lit("")), F.lit(salt))

    # Gera o hash SHA-256
    return F.sha2(salted_value, 256)
    
def validate_pii_masking(df: DataFrame, logger=None) -> None:
    """
    Valida que dados sens√≠veis (PII) est√£o adequadamente mascarados
    
    Args:
        df: DataFrame a ser validado
        logger: Logger opcional para mensagens
        
    Raises:
        ValidationException: Se dados sens√≠veis n√£o estiverem mascarados
    """
    if logger is None:
        logger = setup_logger(__name__)
    
    try:
        logger.info("üîí Validando mascaramento de dados sens√≠veis (PII)...")
        
        # Verificar se coluna numero_cartao_masked existe
        if "numero_cartao_masked" not in df.columns:
            raise ValidationException("Coluna numero_cartao_masked n√£o encontrada no DataFrame")
        
        # Amostrar alguns valores para valida√ß√£o
        sample_df = df.select("numero_cartao_masked").limit(10)
        
        for row in sample_df.collect():
            masked_card = row["numero_cartao_masked"]
            
            if masked_card:
                # Verificar se cont√©m apenas d√≠gitos e asteriscos
                if not all(c.isdigit() or c == '*' for c in str(masked_card)):
                    raise ValidationException(
                        f"N√∫mero de cart√£o mascarado cont√©m caracteres inv√°lidos: {masked_card}"
                    )
                
                # Verificar se tem exatamente 6 d√≠gitos iniciais + 6 asteriscos + 4 d√≠gitos finais
                expected_length = 16  # 6 + 6 + 4
                if len(str(masked_card)) != expected_length:
                    raise ValidationException(
                        f"N√∫mero de cart√£o mascarado tem comprimento incorreto: {masked_card} "
                        f"(esperado: {expected_length}, obtido: {len(str(masked_card))})"
                    )
                
                # Verificar se os primeiros 6 s√£o d√≠gitos
                first_six = str(masked_card)[:6]
                if not first_six.isdigit():
                    raise ValidationException(
                        f"Primeiros 6 d√≠gitos do cart√£o mascarado n√£o s√£o v√°lidos: {first_six}"
                    )
                
                # Verificar se h√° asteriscos no meio (posi√ß√µes 7-12)
                middle = str(masked_card)[6:12]
                if middle != "******":
                    raise ValidationException(
                        f"Parte mascarada do cart√£o n√£o est√° correta: {middle} "
                        f"(esperado: ******)"
                    )
                
                # Verificar se os √∫ltimos 4 s√£o d√≠gitos
                last_four = str(masked_card)[-4:]
                if not last_four.isdigit():
                    raise ValidationException(
                        f"√öltimos 4 d√≠gitos do cart√£o mascarado n√£o s√£o v√°lidos: {last_four}"
                    )
        
        logger.info("‚úì Mascaramento de n√∫meros de cart√£o validado com sucesso")
        
        # Verificar hashes de dados sens√≠veis
        if "numero_cartao_hash" in df.columns:
            hash_sample = df.select("numero_cartao_hash").limit(5)
            for row in hash_sample.collect():
                hash_value = row["numero_cartao_hash"]
                if hash_value:
                    # Verificar se √© hash SHA-256 (64 caracteres hexadecimais)
                    if not (len(str(hash_value)) == 64 and all(c in '0123456789abcdefABCDEF' for c in str(hash_value))):
                        raise ValidationException(
                            f"Hash do n√∫mero do cart√£o n√£o est√° no formato correto: {hash_value}"
                        )
            
            logger.info("‚úì Hash SHA-256 de n√∫meros de cart√£o validado com sucesso")
        
        if "email_hash" in df.columns:
            email_hash_sample = df.select("email_hash").limit(5)
            for row in email_hash_sample.collect():
                hash_value = row["email_hash"]
                if hash_value:
                    # Verificar se √© hash SHA-256 (64 caracteres hexadecimais)
                    if not (len(str(hash_value)) == 64 and all(c in '0123456789abcdefABCDEF' for c in str(hash_value))):
                        raise ValidationException(
                            f"Hash do email n√£o est√° no formato correto: {hash_value}"
                        )
            
            logger.info("‚úì Hash SHA-256 de emails validado com sucesso")
        
        logger.info("‚úÖ Valida√ß√£o completa de PII: todos os dados sens√≠veis est√£o adequadamente mascarados")
        
    except Exception as e:
        logger.error(f"‚úó Erro na valida√ß√£o de PII: {str(e)}")
        raise ValidationException(f"Falha na valida√ß√£o de mascaramento PII: {str(e)}")
        
def validate_no_full_pan_in_output(df: DataFrame, logger=None) -> None:
    """
    Verifica√ß√£o adicional: garante que N√ÉO h√° n√∫meros de cart√£o completos (16 d√≠gitos) no output

    Esta √© uma camada extra de seguran√ßa para detectar vazamentos acidentais de PAN.

    Args:
        df: DataFrame a ser verificado
        logger: Logger opcional

    Raises:
        ValidationException: Se n√∫meros de cart√£o completos forem encontrados
    """
    if logger is None:
        logger = setup_logger(__name__)

    try:
        logger.info("üîç Verifica√ß√£o adicional: buscando n√∫meros de cart√£o completos no output...")

        # Regex para detectar padr√µes de 16 d√≠gitos seguidos
        # Isso pode aparecer em qualquer coluna de string
        string_columns = [field.name for field in df.schema.fields if field.dataType.simpleString() == 'string']

        if not string_columns:
            logger.info("‚úì Nenhuma coluna de string encontrada - verifica√ß√£o n√£o aplic√°vel")
            return

        # Amostrar dados para verifica√ß√£o (limitar para performance)
        sample_df = df.select(*string_columns).limit(100)  # Amostra de 100 linhas

        pan_pattern = r'\b\d{16}\b'  # 16 d√≠gitos seguidos

        for col in string_columns:
            for row in sample_df.collect():
                value = str(row[col]) if row[col] is not None else ""

                # Verificar se h√° 16 d√≠gitos seguidos (PAN completo)
                if re.search(pan_pattern, value):
                    raise ValidationException(
                        f"üö® VAZAMENTO DETECTADO! N√∫mero de cart√£o completo encontrado "
                        f"na coluna '{col}': {value[:50]}..."
                    )

        logger.info("‚úÖ Verifica√ß√£o adicional: nenhum n√∫mero de cart√£o completo encontrado no output")

    except Exception as e:
        logger.error(f"‚úó Erro na verifica√ß√£o de PAN completo: {str(e)}")
        raise ValidationException(f"Falha na verifica√ß√£o de seguran√ßa PAN: {str(e)}")
