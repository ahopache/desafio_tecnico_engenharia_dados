# Docker - SiCooperative Data Lake POC

Este diret√≥rio cont√©m os arquivos Docker para execu√ß√£o automatizada do pipeline ETL.

## üì¶ Arquivos

- **`docker-compose.yml`**: Orquestra√ß√£o dos servi√ßos (MySQL + Spark)
- **`Dockerfile`**: Imagem customizada do ambiente Spark
- **`run-pipeline.sh`**: Script de execu√ß√£o para Linux/Mac
- **`run-pipeline.bat`**: Script de execu√ß√£o para Windows

## üöÄ In√≠cio R√°pido

### 1. Subir o Ambiente

```bash
# No diret√≥rio docker/
docker-compose up -d
```

**O que acontece:**
- MySQL √© iniciado na porta 3306
- Scripts SQL s√£o executados automaticamente (`01_create_schema.sql`, `02_insert_data.sql`)
- Container Spark √© criado com todas as depend√™ncias

### 2. Verificar Status

```bash
docker-compose ps
```

Voc√™ deve ver:
```
NAME                    STATUS              PORTS
sicooperative-mysql     Up (healthy)        0.0.0.0:3306->3306/tcp
sicooperative-spark     Up                  
```

### 3. Executar o Pipeline

**Op√ß√£o A: Script Automatizado (Recomendado)**

```bash
# Linux/Mac
./run-pipeline.sh

# Windows
run-pipeline.bat
```

**Op√ß√£o B: Comando Direto**

```bash
docker-compose exec spark python src/etl_pipeline.py
```

**Op√ß√£o C: Com Argumentos Customizados**

```bash
docker-compose exec spark python src/etl_pipeline.py --output /app/output --log-level DEBUG
```

### 4. Verificar Resultado

```bash
# Listar arquivos gerados
ls -lh ../output/

# Ver primeiras linhas do CSV
head ../output/movimento_flat.csv
```

### 5. Parar o Ambiente

```bash
# Parar containers (mant√©m dados)
docker-compose stop

# Parar e remover containers (mant√©m volumes)
docker-compose down

# Remover tudo (incluindo dados do MySQL)
docker-compose down -v
```

## üîß Comandos √öteis

### Logs

```bash
# Ver logs de todos os servi√ßos
docker-compose logs -f

# Ver logs apenas do MySQL
docker-compose logs -f mysql

# Ver logs apenas do Spark
docker-compose logs -f spark
```

### Acessar Containers

```bash
# Acessar shell do MySQL
docker-compose exec mysql mysql -u root -p sicooperative_db

# Acessar shell do Spark
docker-compose exec spark bash

# Executar query SQL (senha ser√° solicitada)
docker-compose exec mysql mysql -u root -p sicooperative_db -e "SELECT COUNT(*) FROM movimento;"
```

### Rebuild

```bash
# Rebuild da imagem Spark (ap√≥s mudan√ßas no Dockerfile)
docker-compose build --no-cache spark

# Rebuild e restart
docker-compose up -d --build
```

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DOCKER COMPOSE                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   MySQL Container   ‚îÇ         ‚îÇ   Spark Container   ‚îÇ    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
‚îÇ  ‚îÇ - MySQL 8.0         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ - Python 3.10       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - Port 3306         ‚îÇ  JDBC   ‚îÇ - PySpark 3.5       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - Auto-init SQL     ‚îÇ         ‚îÇ - Java 17           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ - Volume: mysql_data‚îÇ         ‚îÇ - MySQL Connector   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ           ‚îÇ                                ‚îÇ                ‚îÇ
‚îÇ           ‚îÇ                                ‚îÇ                ‚îÇ
‚îÇ           ‚ñº                                ‚ñº                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Volume: mysql_data ‚îÇ         ‚îÇ  Volume: output/    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  (Persist√™ncia)     ‚îÇ         ‚îÇ  (CSV gerado)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîê Seguran√ßa e Credenciais

### Configura√ß√£o Segura

**IMPORTANTE**: Este ambiente usa Docker Secrets para proteger credenciais sens√≠veis.

#### 1. Criar Arquivos de Secrets

Antes de executar o ambiente, crie os arquivos de secrets:

```bash
# Navegar para o diret√≥rio docker
cd docker

# Criar diret√≥rio de secrets
mkdir -p secrets

# Gerar senhas seguras (use openssl ou pwgen)
echo "sua_senha_mysql_segura_aqui" > secrets/mysql_root_password
echo "sua_senha_usuario_segura_aqui" > secrets/mysql_password

# Definir permiss√µes restritivas
chmod 600 secrets/mysql_root_password secrets/mysql_password
```

#### 2. Configurar Vari√°veis de Ambiente

Crie um arquivo `.env` baseado no `.env.example`:

```bash
# Copiar template
cp ../.env.example ../.env

# Editar .env com suas configura√ß√µes
nano ../.env
```

#### 3. Configura√ß√µes Padr√£o (Ambiente de Desenvolvimento)

**MySQL:**
- Host: `localhost` (ou `mysql` dentro da rede Docker)
- Port: `3306`
- Database: `sicooperative_db`
- Root User: Definido em `secrets/mysql_root_password`
- App User: Definido em `secrets/mysql_password`

‚ö†Ô∏è **IMPORTANTE**: Estas s√£o configura√ß√µes de desenvolvimento. **NUNCA** use em produ√ß√£o!

### Arquivos de Secrets

O sistema utiliza Docker Secrets para proteger credenciais:

- `secrets/mysql_root_password`: Senha do usu√°rio root do MySQL
- `secrets/mysql_password`: Senha do usu√°rio da aplica√ß√£o

**Para desenvolvimento local:**
```bash
# Criar secrets para desenvolvimento
echo "root_password" > secrets/mysql_root_password
echo "etl_password" > secrets/mysql_password
```

**Para produ√ß√£o:**
- Use sistemas de gerenciamento de segredos (Vault, AWS Secrets Manager, etc.)
- Gere senhas fortes e √∫nicas
- Monitore acessos e altera√ß√µes

## üìä Volumes

### `mysql_data`
- **Prop√≥sito**: Persistir dados do MySQL
- **Localiza√ß√£o**: Gerenciado pelo Docker
- **Backup**: `docker run --rm -v sicooperative-mysql-data:/data -v $(pwd):/backup ubuntu tar czf /backup/mysql-backup.tar.gz /data`

### `../output`
- **Prop√≥sito**: Armazenar CSV gerado
- **Localiza√ß√£o**: `output/` no diret√≥rio raiz do projeto
- **Acesso**: Diretamente no host

## üåê Networking

- **Rede**: `sicooperative-network` (bridge)
- **Comunica√ß√£o**: Containers se comunicam via nomes de servi√ßo
- **Isolamento**: Rede isolada do host (exceto portas expostas)

## üêõ Troubleshooting

### Problema: MySQL n√£o inicia

```bash
# Ver logs
docker-compose logs mysql

# Verificar se porta 3306 j√° est√° em uso
netstat -an | grep 3306  # Linux/Mac
netstat -an | findstr 3306  # Windows

# Remover volume e recriar
docker-compose down -v
docker-compose up -d
```

### Problema: Scripts SQL n√£o executam

```bash
# Verificar se scripts est√£o montados
docker-compose exec mysql ls -la /docker-entrypoint-initdb.d/

# For√ßar execu√ß√£o manual (senha ser√° solicitada)
docker-compose exec mysql mysql -u root -p sicooperative_db < ../sql/01_create_schema.sql
docker-compose exec mysql mysql -u root -p sicooperative_db < ../sql/02_insert_data.sql
```

### Problema: Spark n√£o encontra MySQL

```bash
# Verificar conectividade
docker-compose exec spark ping -c 3 mysql

# Verificar se MySQL est√° healthy
docker-compose ps

# Testar conex√£o JDBC
docker-compose exec spark python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
df = spark.read.format('jdbc').option('url', 'jdbc:mysql://mysql:3306/sicooperative_db').option('user', 'root').option('password', open('/run/secrets/mysql_root_password').read().strip()).option('driver', 'com.mysql.cj.jdbc.Driver').option('dbtable', '(SELECT 1) AS test').load()
print(df.count())
"
```

### Problema: Permiss√µes no Windows

```bash
# Executar PowerShell como Administrador
Set-ExecutionPolicy RemoteSigned -Scope CurrentUser

# Ou usar Docker Desktop com WSL2
```

## üìù Notas

- **Primeira execu√ß√£o**: Pode demorar alguns minutos para baixar imagens e inicializar
- **Reinicializa√ß√µes**: MySQL preserva dados entre reinicializa√ß√µes (volume persistente)
- **Performance**: Ajuste mem√≥ria do Spark em `docker-compose.yml` conforme necess√°rio
- **Produ√ß√£o**: Este setup √© para desenvolvimento/demonstra√ß√£o. Para produ√ß√£o, use secrets, SSL, etc.

## üîÑ Workflow Completo

```bash
# 1. Subir ambiente
cd docker
docker-compose up -d

# 2. Aguardar MySQL (autom√°tico via healthcheck)
docker-compose ps

# 3. Executar pipeline
./run-pipeline.sh  # ou run-pipeline.bat no Windows

# 4. Verificar resultado
head ../output/movimento_flat.csv

# 5. Parar ambiente
docker-compose down
```

## üìö Refer√™ncias

- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [MySQL Docker Image](https://hub.docker.com/_/mysql)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
