# Docker - SiCooperative Data Lake POC

Este diretÃ³rio contÃ©m os arquivos Docker para execuÃ§Ã£o automatizada do pipeline ETL.

## ğŸ“¦ Arquivos

- **`docker-compose.yml`**: OrquestraÃ§Ã£o dos serviÃ§os (MySQL + Spark)
- **`Dockerfile`**: Imagem customizada do ambiente Spark
- **`run-pipeline.sh`**: Script de execuÃ§Ã£o para Linux/Mac
- **`run-pipeline.bat`**: Script de execuÃ§Ã£o para Windows

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Subir o Ambiente

```bash
# No diretÃ³rio docker/
docker-compose up -d
```

**O que acontece:**
- MySQL Ã© iniciado na porta 3306
- Scripts SQL sÃ£o executados automaticamente (`01_create_schema.sql`, `02_insert_data.sql`)
- Container Spark Ã© criado com todas as dependÃªncias

### 2. Verificar Status

```bash
docker-compose ps
```

VocÃª deve ver:
```
NAME                    STATUS              PORTS
sicooperative-mysql     Up (healthy)        0.0.0.0:3306->3306/tcp
sicooperative-spark     Up                  
```

### 3. Executar o Pipeline

**OpÃ§Ã£o A: Script Automatizado (Recomendado)**

```bash
# Linux/Mac
./run-pipeline.sh

# Windows
run-pipeline.bat
```

**OpÃ§Ã£o B: Comando Direto**

```bash
docker-compose exec spark python src/etl_pipeline.py
```

**OpÃ§Ã£o C: Com Argumentos Customizados**

```bash
docker-compose exec spark python src/etl_pipeline.py --output /app/output --log-level DEBUG
```

### 4. Verificar Resultado

```bash
# Listar arquivos gerados
ls -lh ../output/

# Ver primeiras linhas do CSV
head ../output/movimento_flat.csv
```

### 5. Parar o Ambiente

```bash
# Parar containers (mantÃ©m dados)
docker-compose stop

# Parar e remover containers (mantÃ©m volumes)
docker-compose down

# Remover tudo (incluindo dados do MySQL)
docker-compose down -v
```

## ğŸ”§ Comandos Ãšteis

### Logs

```bash
# Ver logs de todos os serviÃ§os
docker-compose logs -f

# Ver logs apenas do MySQL
docker-compose logs -f mysql

# Ver logs apenas do Spark
docker-compose logs -f spark
```

### Acessar Containers

```bash
# Acessar shell do MySQL
docker-compose exec mysql mysql -u root -proot_password sicooperative_db

# Acessar shell do Spark
docker-compose exec spark bash

# Executar query SQL
docker-compose exec mysql mysql -u root -proot_password sicooperative_db -e "SELECT COUNT(*) FROM movimento;"
```

### Rebuild

```bash
# Rebuild da imagem Spark (apÃ³s mudanÃ§as no Dockerfile)
docker-compose build --no-cache spark

# Rebuild e restart
docker-compose up -d --build
```

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER COMPOSE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   MySQL Container   â”‚         â”‚   Spark Container   â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ - MySQL 8.0         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - Python 3.10       â”‚    â”‚
â”‚  â”‚ - Port 3306         â”‚  JDBC   â”‚ - PySpark 3.5       â”‚    â”‚
â”‚  â”‚ - Auto-init SQL     â”‚         â”‚ - Java 17           â”‚    â”‚
â”‚  â”‚ - Volume: mysql_dataâ”‚         â”‚ - MySQL Connector   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                â”‚                â”‚
â”‚           â”‚                                â”‚                â”‚
â”‚           â–¼                                â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Volume: mysql_data â”‚         â”‚  Volume: output/    â”‚    â”‚
â”‚  â”‚  (PersistÃªncia)     â”‚         â”‚  (CSV gerado)       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Credenciais PadrÃ£o

**MySQL:**
- Host: `localhost` (ou `mysql` dentro da rede Docker)
- Port: `3306`
- Database: `sicooperative_db`
- Root User: `root`
- Root Password: `root_password`
- App User: `etl_user`
- App Password: `etl_password`

âš ï¸ **IMPORTANTE**: Estas sÃ£o credenciais de desenvolvimento. **NUNCA** use em produÃ§Ã£o!

## ğŸ“Š Volumes

### `mysql_data`
- **PropÃ³sito**: Persistir dados do MySQL
- **LocalizaÃ§Ã£o**: Gerenciado pelo Docker
- **Backup**: `docker run --rm -v sicooperative-mysql-data:/data -v $(pwd):/backup ubuntu tar czf /backup/mysql-backup.tar.gz /data`

### `../output`
- **PropÃ³sito**: Armazenar CSV gerado
- **LocalizaÃ§Ã£o**: `output/` no diretÃ³rio raiz do projeto
- **Acesso**: Diretamente no host

## ğŸŒ Networking

- **Rede**: `sicooperative-network` (bridge)
- **ComunicaÃ§Ã£o**: Containers se comunicam via nomes de serviÃ§o
- **Isolamento**: Rede isolada do host (exceto portas expostas)

## ğŸ› Troubleshooting

### Problema: MySQL nÃ£o inicia

```bash
# Ver logs
docker-compose logs mysql

# Verificar se porta 3306 jÃ¡ estÃ¡ em uso
netstat -an | grep 3306  # Linux/Mac
netstat -an | findstr 3306  # Windows

# Remover volume e recriar
docker-compose down -v
docker-compose up -d
```

### Problema: Scripts SQL nÃ£o executam

```bash
# Verificar se scripts estÃ£o montados
docker-compose exec mysql ls -la /docker-entrypoint-initdb.d/

# ForÃ§ar execuÃ§Ã£o manual
docker-compose exec mysql mysql -u root -proot_password sicooperative_db < ../sql/01_create_schema.sql
docker-compose exec mysql mysql -u root -proot_password sicooperative_db < ../sql/02_insert_data.sql
```

### Problema: Spark nÃ£o encontra MySQL

```bash
# Verificar conectividade
docker-compose exec spark ping -c 3 mysql

# Verificar se MySQL estÃ¡ healthy
docker-compose ps

# Testar conexÃ£o JDBC
docker-compose exec spark python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
df = spark.read.format('jdbc').option('url', 'jdbc:mysql://mysql:3306/sicooperative_db').option('user', 'root').option('password', 'root_password').option('driver', 'com.mysql.cj.jdbc.Driver').option('dbtable', '(SELECT 1) AS test').load()
print(df.count())
"
```

### Problema: PermissÃµes no Windows

```bash
# Executar PowerShell como Administrador
Set-ExecutionPolicy RemoteSigned -Scope CurrentUser

# Ou usar Docker Desktop com WSL2
```

## ğŸ“ Notas

- **Primeira execuÃ§Ã£o**: Pode demorar alguns minutos para baixar imagens e inicializar
- **ReinicializaÃ§Ãµes**: MySQL preserva dados entre reinicializaÃ§Ãµes (volume persistente)
- **Performance**: Ajuste memÃ³ria do Spark em `docker-compose.yml` conforme necessÃ¡rio
- **ProduÃ§Ã£o**: Este setup Ã© para desenvolvimento/demonstraÃ§Ã£o. Para produÃ§Ã£o, use secrets, SSL, etc.

## ğŸ”„ Workflow Completo

```bash
# 1. Subir ambiente
cd docker
docker-compose up -d

# 2. Aguardar MySQL (automÃ¡tico via healthcheck)
docker-compose ps

# 3. Executar pipeline
./run-pipeline.sh  # ou run-pipeline.bat no Windows

# 4. Verificar resultado
head ../output/movimento_flat.csv

# 5. Parar ambiente
docker-compose down
```

## ğŸ“š ReferÃªncias

- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [MySQL Docker Image](https://hub.docker.com/_/mysql)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
