# Testes UnitÃ¡rios - SiCooperative Data Lake POC

Este diretÃ³rio contÃ©m os testes unitÃ¡rios para validar o pipeline ETL.

## ğŸ“‹ Estrutura

```
tests/
â”œâ”€â”€ __init__.py                 # InicializaÃ§Ã£o do pacote de testes
â”œâ”€â”€ conftest.py                 # Fixtures compartilhadas (sessÃ£o Spark, dados de exemplo)
â”œâ”€â”€ test_config.py              # Testes do mÃ³dulo config.py
â”œâ”€â”€ test_utils.py               # Testes do mÃ³dulo utils.py
â”œâ”€â”€ test_etl_pipeline.py        # Testes do pipeline ETL principal
â””â”€â”€ README.md                   # Este arquivo
```

## ğŸ§ª Cobertura de Testes

### **test_config.py** (15 testes)
Valida configuraÃ§Ãµes e mÃ©todos de configuraÃ§Ã£o:
- âœ… Formato da URL JDBC
- âœ… Propriedades de conexÃ£o MySQL
- âœ… ConfiguraÃ§Ãµes do Spark
- âœ… ConstruÃ§Ã£o de caminhos de output
- âœ… ValidaÃ§Ã£o de configuraÃ§Ãµes obrigatÃ³rias
- âœ… Nomes e tipos de colunas

### **test_utils.py** (13 testes)
Valida funÃ§Ãµes auxiliares:
- âœ… Setup de logger
- âœ… ValidaÃ§Ã£o de DataFrames (linhas mÃ­nimas, colunas obrigatÃ³rias)
- âœ… FormataÃ§Ã£o de duraÃ§Ã£o (segundos, minutos, horas)
- âœ… ExceÃ§Ãµes customizadas

### **test_etl_pipeline.py** (16 testes)
Valida o pipeline ETL completo:
- âœ… JOINs individuais (movimento+cartao, cartao+conta, conta+associado)
- âœ… Cadeia completa de JOINs
- âœ… RenomeaÃ§Ã£o de colunas
- âœ… ConversÃ£o de tipos de dados
- âœ… FormataÃ§Ã£o de datas
- âœ… Integridade de dados (sem perda em JOINs)
- âœ… Qualidade de dados (sem nulos, valores positivos)
- âœ… CriaÃ§Ã£o de instÃ¢ncia do ETL
- âœ… MÃ©todo transform_and_join

**Total: 44 testes**

## ğŸš€ Executar Testes

### Todos os testes

```bash
# No diretÃ³rio raiz do projeto
pytest

# Ou com mais detalhes
pytest -v

# Com output colorido
pytest --color=yes
```

### Testes especÃ­ficos

```bash
# Apenas testes de config
pytest tests/test_config.py

# Apenas testes de utils
pytest tests/test_utils.py

# Apenas testes do pipeline
pytest tests/test_etl_pipeline.py

# Teste especÃ­fico
pytest tests/test_config.py::TestConfig::test_mysql_jdbc_url_format
```

### Com cobertura

```bash
# Executar com relatÃ³rio de cobertura
pytest --cov=src --cov-report=html

# Ver relatÃ³rio
# Windows: start htmlcov/index.html
# Linux/Mac: open htmlcov/index.html

# RelatÃ³rio no terminal
pytest --cov=src --cov-report=term-missing
```

### Dentro do Docker

```bash
# Executar testes no container Spark
docker-compose exec spark pytest

# Com cobertura
docker-compose exec spark pytest --cov=src --cov-report=term-missing

# Testes especÃ­ficos
docker-compose exec spark pytest tests/test_etl_pipeline.py -v
```

## ğŸ“Š Fixtures DisponÃ­veis

### SessÃ£o Spark
- **`spark`**: SessÃ£o Spark configurada para testes (scope: session)

### Dados de Exemplo
- **`sample_associado_data`**: Lista com 3 associados
- **`sample_conta_data`**: Lista com 3 contas
- **`sample_cartao_data`**: Lista com 3 cartÃµes
- **`sample_movimento_data`**: Lista com 4 movimentos

### DataFrames
- **`df_associado`**: DataFrame de associados
- **`df_conta`**: DataFrame de contas
- **`df_cartao`**: DataFrame de cartÃµes
- **`df_movimento`**: DataFrame de movimentos

### Outros
- **`expected_output_columns`**: Lista com as 11 colunas esperadas no output

## ğŸ”§ ConfiguraÃ§Ã£o

### pytest.ini

ConfiguraÃ§Ãµes do pytest no arquivo `pytest.ini` na raiz do projeto:
- DiretÃ³rios de teste: `tests/`
- PadrÃµes de arquivos: `test_*.py`
- Markers customizados: `slow`, `integration`, `unit`
- ConfiguraÃ§Ã£o de cobertura

### conftest.py

Fixtures compartilhadas entre todos os testes:
- SessÃ£o Spark Ãºnica para todos os testes (performance)
- Dados de exemplo consistentes
- Schemas definidos para cada tabela

## ğŸ“ Boas PrÃ¡ticas Implementadas

### OrganizaÃ§Ã£o
- âœ… Testes agrupados em classes por funcionalidade
- âœ… Nomes descritivos de testes
- âœ… Fixtures reutilizÃ¡veis

### Cobertura
- âœ… Testes unitÃ¡rios para funÃ§Ãµes individuais
- âœ… Testes de integraÃ§Ã£o para fluxo completo
- âœ… Testes de qualidade de dados

### Assertions
- âœ… Uso de `assert_df_equality` do chispa para DataFrames
- âœ… ValidaÃ§Ãµes especÃ­ficas (tipos, valores, contagens)
- âœ… Mensagens de erro claras

### Performance
- âœ… SessÃ£o Spark compartilhada (scope: session)
- âœ… Dados de exemplo pequenos
- âœ… ConfiguraÃ§Ãµes otimizadas (2 partitions, 2 cores)

## ğŸ› Troubleshooting

### Erro: "No module named 'src'"

```bash
# Adicionar src ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"  # Linux/Mac
set PYTHONPATH=%PYTHONPATH%;%cd%\src          # Windows CMD
$env:PYTHONPATH += ";$(pwd)\src"              # Windows PowerShell

# Ou executar do diretÃ³rio raiz
cd desafio_tecnico_engenharia_dados
pytest
```

### Erro: "Java not found"

```bash
# Instalar Java (requerido pelo Spark)
# Ubuntu/Debian
sudo apt-get install openjdk-17-jre-headless

# Windows: Baixar e instalar Java JDK 17
# https://www.oracle.com/java/technologies/downloads/

# Verificar instalaÃ§Ã£o
java -version
```

### Erro: "MySQL Connector not found"

```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Ou especificamente
pip install mysql-connector-python
```

### Testes lentos

```bash
# Executar apenas testes rÃ¡pidos (excluir marcados como slow)
pytest -m "not slow"

# Executar em paralelo (requer pytest-xdist)
pip install pytest-xdist
pytest -n auto
```

## ğŸ“š Frameworks Utilizados

- **pytest**: Framework de testes principal
- **chispa**: ComparaÃ§Ã£o de DataFrames Spark
- **pytest-cov**: RelatÃ³rios de cobertura
- **PySpark**: Testes de transformaÃ§Ãµes Spark

## ğŸ¯ PrÃ³ximos Passos

### Melhorias Futuras
- [ ] Testes de integraÃ§Ã£o com MySQL real
- [ ] Testes de performance (grandes volumes)
- [ ] Testes de falhas e recuperaÃ§Ã£o
- [ ] Mocks para conexÃµes externas
- [ ] Testes de concorrÃªncia
- [ ] Property-based testing (hypothesis)

### CI/CD
- [ ] IntegraÃ§Ã£o com GitHub Actions
- [ ] ExecuÃ§Ã£o automÃ¡tica em PRs
- [ ] RelatÃ³rios de cobertura no PR
- [ ] Badge de status no README

## ğŸ“– ReferÃªncias

- [pytest Documentation](https://docs.pytest.org/)
- [chispa Documentation](https://github.com/MrPowers/chispa)
- [PySpark Testing Best Practices](https://spark.apache.org/docs/latest/api/python/getting_started/testing_pyspark.html)
